{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7beff932",
   "metadata": {},
   "source": [
    "## Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82f84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2102b12",
   "metadata": {},
   "source": [
    "PyTorch, a framework for building and training neural networks. PyTorch in a lot of ways behaves like the arrays you love from Numpy. These Numpy arrays, after all, are just tensors. PyTorch takes these tensors and makes it simple to move them to GPUs for the faster processing needed when training neural networks. It also provides a module that automatically calculates gradients (for backpropagation!) and another module specifically for building neural networks. All together, PyTorch ends up being more coherent with Python and the Numpy/Scipy stack compared to TensorFlow and other frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b57985",
   "metadata": {},
   "source": [
    "Start by loading the dataset through torchvision. \n",
    "Load the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fae0e8",
   "metadata": {},
   "source": [
    "MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d725c43",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f776fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karthik/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1631631227379/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "#transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f827cdb5",
   "metadata": {},
   "source": [
    "This is what an image in the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3573eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f87e8",
   "metadata": {},
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804f68f",
   "metadata": {},
   "source": [
    "Here I'll create a model like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5ed761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6312617a",
   "metadata": {},
   "source": [
    "With the probabilities, we can get the most likely class using the `ps.topk` method. This returns the $k$ highest values. Since we just want the most likely class, we can use `ps.topk(1)`. This returns a tuple of the top-$k$ values and the top-$k$ indices. If the highest value is the fifth element, we'll get back 4 as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a4bef1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(images))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7fb9d9",
   "metadata": {},
   "source": [
    "The goal of validation is to measure the model's performance on data that isn't part of the training set. Performance here is up to the developer to define though. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2699b841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7],\n",
      "        [0],\n",
      "        [1],\n",
      "        [7],\n",
      "        [7],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [6],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "# Look at the most likely classes for the first 10 examples\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08d49e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 14.0625%\n"
     ]
    }
   ],
   "source": [
    "equals = top_class == labels.reshape(*top_class.shape)\n",
    "\n",
    "# We'll need to convert equals to a float tensor\n",
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02689c4f",
   "metadata": {},
   "source": [
    "The network is untrained so it's making random guesses and we should see an accuracy around 10%. Now let's train our network and include our validation pass so we can measure how well the network is performing on the test set. Since we're not updating our parameters in the validation pass, we can speed up our code by turning off gradients using `torch.no_grad()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949d061",
   "metadata": {},
   "source": [
    "# Build the Validation pass and check for accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a5b8c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.25%\n",
      "Accuracy: 87.5%\n",
      "Accuracy: 81.25%\n",
      "Accuracy: 87.5%\n",
      "Accuracy: 87.5%\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        train_loss = criterion(log_ps, labels)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += train_loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in trainloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.reshape(*top_class.shape)\n",
    "                accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56926d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fca35396eb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(test_losses,label='Validation loss')\n",
    "plt.plot(train_losses,label='Training loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0d8f2",
   "metadata": {},
   "source": [
    "If we look at the training and validation losses as we train the network, we can see a phenomenon known as \"overfitting\".\n",
    "\n",
    "The most common method to reduce overfitting (outside of early-stopping) is dropout, where we randomly drop input units. This forces the network to share information between weights, increasing it's ability to generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f080c02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(784,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,64)\n",
    "        self.out = nn.Linear(64,10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "       # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "            \n",
    "         # forward pass thro the network with activation and dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "            \n",
    "            #  No dropout for the output\n",
    "        x = F.log_softmax(self.out(x), dim=1)\n",
    "            \n",
    "        return x\n",
    "        \n",
    "model = Network() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fba4021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 0.604..  Test Loss: 0.004..  Test Accuracy: 0.835\n",
      "Epoch: 2/10..  Training Loss: 0.483..  Test Loss: 0.006..  Test Accuracy: 0.844\n",
      "Epoch: 3/10..  Training Loss: 0.453..  Test Loss: 0.003..  Test Accuracy: 0.847\n",
      "Epoch: 4/10..  Training Loss: 0.434..  Test Loss: 0.004..  Test Accuracy: 0.856\n",
      "Epoch: 5/10..  Training Loss: 0.425..  Test Loss: 0.004..  Test Accuracy: 0.858\n",
      "Epoch: 6/10..  Training Loss: 0.413..  Test Loss: 0.002..  Test Accuracy: 0.854\n",
      "Epoch: 7/10..  Training Loss: 0.408..  Test Loss: 0.001..  Test Accuracy: 0.855\n",
      "Epoch: 8/10..  Training Loss: 0.401..  Test Loss: 0.002..  Test Accuracy: 0.857\n",
      "Epoch: 9/10..  Training Loss: 0.393..  Test Loss: 0.005..  Test Accuracy: 0.852\n",
      "Epoch: 10/10..  Training Loss: 0.387..  Test Loss: 0.003..  Test Accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "## TODO: Train your model with dropout, and monitor the training progress with the validation loss and accuracy\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.003)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "steps = 0\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for image, label in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(image)\n",
    "        train_loss = criterion(log_ps,label)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += train_loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad(): # Turn off gradients for validation, saves memory and computations\n",
    "            model.eval()\n",
    "            for image, label in testloader:\n",
    "                out = model(image)\n",
    "                test_loss = criterion(out,label)\n",
    "                \n",
    "                ps = torch.exp(out)\n",
    "                top_p, top_class = ps.topk(1,dim=1)\n",
    "                equals = top_class == label.reshape(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "\n",
    "                \n",
    "        model.train()\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a277b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use the model for making predictions or for testing, switch back to model.eval() mode\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f7576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
